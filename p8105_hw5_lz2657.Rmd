---
title: "p8105_hw5_lz2657"
author: Lingyu Zhang
date: Nov 5, 2018
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(purrr)
library(broom)
```

## Problem 1

First, set up a dataframe containing all file names.

```{r problem1_read_file_names}
  df = list.files(path = "./data/") %>%
    as.tibble()

  df
```

Next, make a reading function, read in data for each subject and save the result as the "observe" variable.

```{r problem1_read_data}
read_csv_function = function(file_name){
  subject =
    read_csv(file = str_c("./data/", file_name)) %>%
    mutate(file = file_name)
}

df = mutate(df, observe = map(.x = df[[1,]], ~ read_csv_function(.x)))
```

Now tidy the result.

```{r problem1_tidy}
df = df%>%
  separate(value, into = c("arm", "number"), sep = "_") %>%
  mutate(number = substr(number, 1, 2)) %>%
  unnest %>%
  gather(key = week, value = data, week_1:week_8) %>%
  mutate(week = substr(week, 6, 6)) %>%
  select(arm, number, week, data)

df
```

Then we can make a spaghetti plot showing observations on each subject over time.

```{r problem1_plot}
ggplot(df, aes(x = week, y = data, color = number, group = number)) + 
  geom_line() + 
  facet_grid( ~ arm) + 
    labs(
      title = "subject observations over time",
      x = "week",
      y = "observation"
    ) +
    viridis::scale_color_viridis(
      name = "ID", 
      discrete = TRUE
    )
```

The observations of the subjects in the control arm almost keep constant and even a little bit decreasing, while those of the experimental arm have an obvious trend of increasing.

## Problem 2

```{r problem2_read_tidy}
homicide_url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data = 
  read.csv(url(homicide_url), stringsAsFactors = FALSE) %>% 
  janitor::clean_names() %>% 
  as_tibble()

homicide_data
```

The raw dataset has `r nrow(homicide_data)` rows of `r ncol(homicide_data)` variables, including uid, reported date, last and first name, race, sex and age of the victims, city, state, latitude, longitude and disposition. All of the dates are from 2007 to 2017. There are four wrong data in the raw dataset. I change these data to what they should be.

```{r problem2_change_data, include = FALSE}
wrong_1 = (1:nrow(homicide_data))[homicide_data[,2] == 201511105]
wrong_2 = (1:nrow(homicide_data))[homicide_data[,2] == 201511018]
wrong_3 = (1:nrow(homicide_data))[homicide_data[,12] == ""]
wrong_4 = (1:nrow(homicide_data))[homicide_data[,8] == "Tulsa" & homicide_data[,9] == "AL"]

homicide_data[wrong_1,2] = 20151105
homicide_data[wrong_2,2] = 20151018
homicide_data[wrong_3,] = c("Pit-000050", 20100702, "SPRINGS", "TY-JAH", "Black", 0, "Female", "Pittsburgh", "PA", 40.461945, -79.89477, "Closed by arrest")
homicide_data[wrong_4,9] = "OK"
```

Now create a city_state variable and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides.

```{r problem2_manipulate}
homicide_data = homicide_data %>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  group_by(city_state) %>%
  summarize(total = n(), 
            unsolved = sum(disposition == "Closed without arrest" | disposition == "Open/No arrest"))

homicide_data
```

